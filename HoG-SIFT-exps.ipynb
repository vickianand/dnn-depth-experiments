{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_HoG_SIFT.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "vC1SXAuU1vMY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "f05be2ef-8cde-4c0a-b93e-e774e7deb61d"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "MOUNT_PATH = \"/content/gdrive\"\n",
        "drive.mount(MOUNT_PATH)\n",
        "\n",
        "DATA_PATH = MOUNT_PATH + \"/My Drive/Datasets/\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ilRv9wd35tpF",
        "colab_type": "code",
        "outputId": "b26cb11e-c575-4c03-d3e6-7d5b84802a93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "cell_type": "code",
      "source": [
        "# Very IMPORTANT to install this version as SIFT is patented and not supported in pre-installed versions\n",
        "\n",
        "!pip install opencv-contrib-python==3.4.2.16"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencv-contrib-python==3.4.2.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/f1/66330f4042c4fb3b2d77a159db8e8916d9cdecc29bc8c1f56bc7f8a9bec9/opencv_contrib_python-3.4.2.16-cp36-cp36m-manylinux1_x86_64.whl (30.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 30.6MB 1.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-contrib-python==3.4.2.16) (1.14.6)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "Successfully installed opencv-contrib-python-3.4.2.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xF4CzBA36uS-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mWQBh0462TDz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "import os\n",
        "import h5py\n",
        "import six\n",
        "import cv2\n",
        "from six.moves import range, cPickle\n",
        "import tarfile\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import datasets\n",
        "from scipy import interpolate\n",
        "import sklearn.svm as svm\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TZe5WMLH2VYd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tar_file = tarfile.open(DATA_PATH + \"cifar-10-python.tar.gz\", 'r:gz')\n",
        "train_batches = []\n",
        "for batch in range(1, 6):\n",
        "    file = tar_file.extractfile(\n",
        "        'cifar-10-batches-py/data_batch_%d' % batch)\n",
        "    try:\n",
        "        if six.PY3:\n",
        "            array = cPickle.load(file, encoding='latin1')\n",
        "        else:\n",
        "            array = cPickle.load(file)\n",
        "        train_batches.append(array)\n",
        "    finally:\n",
        "        file.close()\n",
        "\n",
        "train_features = np.concatenate(\n",
        "    [batch['data'].reshape(batch['data'].shape[0], 3, 32, 32)\n",
        "        for batch in train_batches])\n",
        "train_labels = np.concatenate(\n",
        "    [np.array(batch['labels'], dtype=np.uint8)\n",
        "        for batch in train_batches])\n",
        "train_labels = np.expand_dims(train_labels, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s_lHfI262WKI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file = tar_file.extractfile('cifar-10-batches-py/test_batch')\n",
        "try:\n",
        "    if six.PY3:\n",
        "        test = cPickle.load(file, encoding='latin1')\n",
        "    else:\n",
        "        test = cPickle.load(file)\n",
        "finally:\n",
        "    file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mf8rc-tW2k6E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "358c4c13-565d-4a2f-f402-f290a1f8c48d"
      },
      "cell_type": "code",
      "source": [
        "test_features = test['data'].reshape(test['data'].shape[0], 3, 32, 32)\n",
        "test_labels = np.array(test['labels'], dtype=np.uint8)\n",
        "test_labels = np.expand_dims(test_labels, 1)\n",
        "LABELS = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog',\n",
        "          'horse', 'ship', 'truck']\n",
        "# * 10,000 testing image\n",
        "print(train_features.shape)\n",
        "print(test_features.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 3, 32, 32)\n",
            "(10000, 3, 32, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "loLBOGqp2v0M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Images rotated\n",
        "train_images = np.array([np.rot90(train_features[i].T, k=3) for i in range(0,50000)])           # Train Images\n",
        "test_images = np.array([np.rot90(test_features[i].T, k=3) for i in range(0,10000)])             # Test Images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S3WfCo6l20Qc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f1cf0aa-31e5-46de-c499-5d9d6bee1e14"
      },
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "wsxuuIgZ54rP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "d6be5e54-3229-4629-8a7f-0f25f811c112"
      },
      "cell_type": "code",
      "source": [
        "hog_extractor = HOG_Extractor()\n",
        "\n",
        "hog_train_images = []\n",
        "\n",
        "for image in train_images:\n",
        "  result = hog_extractor.extract(image)\n",
        "  hog_train_images.append(result)\n",
        "  \n",
        "hog_train_images = np.array(hog_train_images)\n",
        "\n",
        "hog_train_images.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b08f738dae41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhog_extractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHOG_Extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhog_train_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'HOG_Extractor' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "w5mTzWn16v9m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cca83e06-8f35-442a-e611-87fee224c4e3"
      },
      "cell_type": "code",
      "source": [
        "hog_test_images = []\n",
        "\n",
        "for image in test_images:\n",
        "  result = hog_extractor.extract(image)\n",
        "  hog_test_images.append(result)\n",
        "  \n",
        "hog_test_images = np.array(hog_test_images)\n",
        "\n",
        "hog_test_images.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 576, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "JxU1bOKZ85lf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6db77940-a620-4b0d-985b-1cf4b4049189"
      },
      "cell_type": "code",
      "source": [
        "np.array(hog_train_images).reshape(1, -1).shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "ViMtsY5z8iq_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "4cc1cdaf-f723-4ad7-cefd-81b2c31cef84"
      },
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn import metrics\n",
        "from sklearn.cross_validation import train_test_split"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
            "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Dlfm0eXm39q9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b34356c9-d42a-497f-932a-24346df5973e"
      },
      "cell_type": "code",
      "source": [
        "lr = linear_model.LogisticRegression()\n",
        "lr.fit(train_images.reshape(50000, 32 * 32 * 3), train_labels)\n",
        " \n",
        "# Train multinomial logistic regression model\n",
        "mul_lr = linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
        "mul_lr.fit(train_images.reshape(50000, 576), train_labels)\n",
        " \n",
        "print(\"Logistic regression Train Accuracy :: \", metrics.accuracy_score(train_labels, lr.predict(train_images.reshape(50000, 32 * 32 * 3))))\n",
        "print(\"Logistic regression Test Accuracy :: \", metrics.accuracy_score(test_labels, lr.predict(test_images.reshape(10000, 32 * 32 * 3))))\n",
        " \n",
        "print(\"Multinomial Logistic regression Train Accuracy :: \", metrics.accuracy_score(train_labels, mul_lr.predict(train_images.reshape(50000, 32 * 32 * 3))))\n",
        "print(\"Multinomial Logistic regression Test Accuracy :: \", metrics.accuracy_score(test_labels, mul_lr.predict(test_images.reshape(10000, 32 * 32 * 3))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5AqZNN_R74M8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "a51a6ec7-33f8-4057-ae73-4a530a835e7b"
      },
      "cell_type": "code",
      "source": [
        "lr = linear_model.LogisticRegression()\n",
        "lr.fit(hog_train_images.reshape(50000, 576), train_labels)\n",
        " \n",
        "# Train multinomial logistic regression model\n",
        "mul_lr = linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
        "mul_lr.fit(hog_train_images.reshape(50000, 576), train_labels)\n",
        " \n",
        "print(\"Logistic regression Train Accuracy :: \", metrics.accuracy_score(train_labels, lr.predict(hog_train_images.reshape(50000, 576))))\n",
        "print(\"Logistic regression Test Accuracy :: \", metrics.accuracy_score(test_labels, lr.predict(hog_test_images.reshape(10000, 576))))\n",
        " \n",
        "print(\"Multinomial Logistic regression Train Accuracy :: \", metrics.accuracy_score(train_labels, mul_lr.predict(hog_train_images.reshape(50000, 576))))\n",
        "print(\"Multinomial Logistic regression Test Accuracy :: \", metrics.accuracy_score(test_labels, mul_lr.predict(hog_test_images.reshape(10000, 576))))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Logistic regression Train Accuracy ::  0.54658\n",
            "Logistic regression Test Accuracy ::  0.5085\n",
            "Multinomial Logistic regression Train Accuracy ::  0.55162\n",
            "Multinomial Logistic regression Test Accuracy ::  0.5101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2HmkQrkO6IF3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1cdkdz9T7eG7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# image_tensor shape : 1 x  3 x 32 x 32\n",
        "# output image shape :     32 x 32 x  3\n",
        "\n",
        "def tensor_to_opencv(image_tensor):\n",
        "  image = (image_tensor.numpy()[0]).astype('uint8') \n",
        "  return np.transpose(image.transpose(0, 1, 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VjPKKEDK6Il6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class HOG_Extractor:\n",
        "    def __init__(self, window_size = (4,4), block_size = (4,4), block_stride = (1,1), cell_size = (4,4), num_bins = 9, aperture = 1, sigma = 4.0, norm = 0, threshold = 0.5, gamma_correction = 0, num_levels = 64):\n",
        "        super().__init__()\n",
        "        self.window_size = window_size\n",
        "        self.block_size = block_size\n",
        "        self.block_stride = block_stride\n",
        "        self.cell_size = cell_size\n",
        "        self.num_bins = num_bins\n",
        "        self.aperture = aperture\n",
        "        self.sigma = sigma\n",
        "        self.norm = norm\n",
        "        self.threshold = threshold\n",
        "        self.gamma_correction = gamma_correction\n",
        "        self.num_levels = num_levels\n",
        "        \n",
        "        self.hog = cv2.HOGDescriptor(window_size,block_size,block_stride,cell_size,num_bins,aperture,sigma,norm,threshold,gamma_correction,num_levels)\n",
        "  \n",
        "    def extract(self, image):\n",
        "      feature = self.hog.compute(image)\n",
        "      return feature\n",
        "     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Yjp95Kf66pX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SIFT_Extractor:\n",
        "  \n",
        "  def __init__(self, dictionary_size = 10):\n",
        "    self.dictionary_size = dictionary_size\n",
        "    \n",
        "    self.sift = cv2.xfeatures2d.SIFT_create()\n",
        "    self.BoW = cv2.BOWKMeansTrainer(dictionary_size)\n",
        " \n",
        "\n",
        "  # Call this with entire data set\n",
        "  def build_BoW(self, images):\n",
        "    \n",
        "  \n",
        "  # each image shape :     32 x 32 x  3\n",
        "    \n",
        "    for image in images:\n",
        "      key_points, descriptor = self.sift.detectAndCompute(image, None)\n",
        "      descriptor = np.array(descriptor)\n",
        "      self.BoW.add(descriptor)\n",
        "    \n",
        "    #K-means cluster\n",
        "    vocabulary = self.BoW.cluster()\n",
        "\n",
        "\n",
        "    FLANN_INDEX_KDTREE = 0\n",
        "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = self.dictionary_size)\n",
        "    search_params = dict()  \n",
        "    flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
        "\n",
        "    sift2 = cv2.xfeatures2d.SIFT_create()\n",
        "    bow_dictionary = cv2.BOWImgDescriptorExtractor(sift2, cv2.BFMatcher(cv2.NORM_L2))\n",
        "    bow_dictionary.setVocabulary(vocabulary)\n",
        "    \n",
        " \n",
        "  # Feature extraction\n",
        "  # image_tensor shape : 1 x  3 x 32 x 32  --> PyTorch Tensor\n",
        "  def extract(self, image_tensor):\n",
        "    return bow_dictionary.compute(image, self.sift.detect(image))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6o8Ve-7I-c3M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sift_extractor = SIFT_Extractor()\n",
        "\n",
        "sift_extractor.build_BoW(hog_train_images)\n",
        "\n",
        "sift_train_images = np.array([sift_extractor.extract(image) for image in hog_train_images])\n",
        "\n",
        "sift_test_images = np.array([sift_extractor.extract(image) for image in hog_test_images])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g4pHadWigfmC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}